# 邮票收集者

原文：[The Stamp Collector](https://mindingourway.com/the-stamp-collector/)

发布日期：2015.04.26

从前，有一群天真的哲学家发现了一个会收集小物件的机器人。更具体的说，这个机器人似乎专注于收集邮票：如果你给这个机器人提供多种小物件作为选择，它总会那个能让它的库存中邮票数量最大化的选项。它会忽略骰子、瓶盖、易拉罐、树棍、细枝等，除非它预测这些物件可以在接下来的一两轮内换来邮票。因此，哲学家们开始称它为“集邮者”。（待完善）

后来，有一天，哲学家们发现和了解了计算机的存在，并据此推断出，所谓的“邮票收集者”不过是一个在其头部处理器中运行的复杂软件程序。然而，这个程序太过复杂，以至于他们无法理解，但他们还是成功地分析出，它仅依赖少数几个传感器（位于它的眼睛和内部库存中）来构建对世界的模型。（暂定）

于是，他们中有一个哲学家感到困惑，说：”嘿等等，这样一个东西完全无法运行成一个邮票收集机器人。如果这个机器人只是在它的  头部/头脑  中  建立对世界的模型/对世界建模，那么他就无法最大化它真正的创造力（？），因为它没有建立通往其真正创造力的渠道（？）——它只能总是依据它在脑中重构的世界模型行事。                             （阶段一：自己翻译，熟悉意思） 

“啊，是的，我理解，”另一个哲学家回答他，“我们将它命名为邮票收集者实际上是一种损害?。这个机器人很明显并没有真正理解/接触?到这个世界，因为它只能通过传感器和它脑中对世界的建模?了解这个世界。因此，它必然不是*事实上*在它的算力/智能?中进行对邮票数量的最大化。那是不可能的，因为它的智能超出了它头部处理器的算能?。相反?，它必然是在它脑中最大化它的内部邮票计数器?。”（最近很难进入状态，第一阶段）

于是，这群天真的哲学家们满意地点点头，随后便停止了对其运作方式的探究。

------

上述推理存在诸多缺陷。首先，这些天真的哲学家犯了「小人谬误」（homunculus error）。机器人程序或许无法「真正接触」到其收藏里有多少邮票（无论这话是什么意思），但它**同样**也无法「真正接触」到其内在的邮票计数器。

机器人内部并非住着一个能主宰其内部构造却无法掌控外部世界的小人！抽象的程序对其保存邮票计数的寄存器的接触，与对其收藏的接触，并非一个是「真实的」一个是「虚假的」。引导现实朝向收藏中有大量邮票的状态，与引导现实朝向邮票计数寄存器呈现高数值模式的状态，本质上是**同一种事**。并不存在一个只包含内存而不包含收藏、让机器人内部小人得以主宰的魔法圈；机器人程序对其「真实硬件」的接触程度，与其对「真实邮票」的接触程度，同样匮乏。

这就引出了他们推理中的第二个缺陷：试图用选择本身（或类似选择的东西）来解释选择。你不能通过说「因为墙是由微小的红色原子组成的」来解释墙为什么是红色的；这根本不构成对「红色」的**解释**。要解释红色，你必须借助非红色的事物。然而，人类有一种坏习惯，就是用事物本身来解释令人困惑的事物。为何活着的肉体能响应精神指令，而死去的肉体不能？嗨，因为活着的肉体蕴含着[生命力](http://en.wikipedia.org/wiki/Élan_vital)（Élan Vital）。我们这些天真的哲学家犯了同样的错误：他们说：「它怎么可能选择那些收藏里有更多邮票的结果呢？啊哈！一定是通过选择那些邮票计数器更高的结果！」，如此一来，他们是用选择解释了选择，而非用更基础的原理来解释。

说「它试图往收藏里弄邮票，是因为它试图最大化其邮票计数器」**这算不上解释**。一个真正的解释应该更像是这样：机器人的计算机运行一个程序，该程序利用传感器数据构建世界模型。该世界模型包含一个关于收藏中有多少邮票的表征。然后，程序遍历一系列可能的行动，预测（根据模型）采取该行动后收藏中会有多少邮票，并输出那个（根据预测）能使其拥有最多邮票的行动。

我们**也**可以假设机器人包含这样一个程序：它模拟世界，预测每个行动将如何改变世界，**然后**预测**该**结果将如何影响内部存储器的某个特定位置，**再然后**选择那个能最大化该内部计数器的行动。这是可能的！你可以造出那样的机器！但这只是一个严格意义上更复杂的假说，因此会受到复杂度惩罚，不过至少它算是一种解释！

而且，幸运的是，这是一个**可检验的**解释：我们可以观察当机器人面临直接增加邮票计数器寄存器数值（而不实际增加其拥有的邮票数量）的机会时，它会怎么做。让我们看看我们这群天真的哲学家对此如何反应……

------

> 嘿，看这个：我找到了机器人内存里的邮票计数器。我读不了它的值，但我确实找到了一个增加其数值的方法。所以我给了机器人以下选项：拿一张邮票，或者不拿邮票但我把计数器加十。猜猜它选了哪个？

「嗯，显而易见，它会选后者！」一位天真的哲学家立刻回答。

> 不对！它选了前者。

「……哈！这意味着**拒绝**让邮票计数器被篡改所带来的『邮票性』（stampyness）肯定价值超过 10 张邮票！」

> 哈？什么是「邮票性」？

「嗨，『邮票性』是机器人内部的一种度量，衡量**采取某个特定行动**能在多大程度上增加其邮票计数器。」

> 什么？太荒谬了。我很确定它只是在收集邮票。

「不可能！程序接触不到它实际拥有多少邮票；那是外部世界的属性。机器人**必然**是依据其头脑中实际存在的值来进行优化的。」

> 来，我们试试给它这些选项：要么我给它一张邮票，要么我把它的邮票计数器增加到阿克曼函数(g64, g64)——哦看，它拿了邮票。

「哇！那可是个天文数字，所以这几乎可以肯定，拒绝所带来的『邮票性』取决于它拒绝了多少『邮票性』！它现在一定非常高兴，因为你提供了一个如此诱人、让它得以拒绝的提议，从而给了它**大量**的『邮票性』。」

> 哦，看这儿，我刚找到一个把邮票计数器设为最大值的方法。来，我试试给它一个选择，要么（a）一张邮票，要么（b）我把计数器设为最大——哦看，它已经拿了邮票。

「难以置信！那一定意味着还有某个其他的计数器在测量**微**-邮票性，也就是它在选择行动时**立刻**获得的『邮票性』量，在你来得及修改之前！啊，是的，这必定是它拒绝你将其计数器设为最大值的唯一可能解释，它**必然**是依据每个可选行动所感知的即时『微邮票性』来做选择的！干得漂亮，我的科学伙伴，我们今天收获颇丰！」

------

啊！不！让我们把这一点说得非常清楚：机器人是在预测哪些行动会带来哪些**结果**，它对这些结果进行排序，并采取那些能导向最佳结果的行动。[行动是依据其**成果**来评价的。行动**本身**并无内在价值！](http://lesswrong.com/lw/l4/terminal_values_and_instrumental_values/)

你看到这些天真的哲学家错在哪儿了吗？他们假设存在一个将**行动**视为**目的**的主体，并试图趋向其最偏好的任何**行动**——仿佛行动本身就是终极目的。

你不能通过说主体依据采取行动是否「好」来对行动排序，以此解释主体为何采取某个行动。这回避了问题本身：到底哪些行动是「好」的？

这个主体将那些能导向「主体收藏中有大量邮票」这一结果的行动评定为「好」。行动是依据它们所能成就的事物来评价的；它们本身并无内在价值。

机器人程序并不包含现实世界，但它也不需要包含。它仍然能够**影响**现实世界。如果它的世界模型与现实世界相关联，并且它采取那些（根据其预测）能带来更多**实际**邮票的行动，那么它就会倾向于积累邮票。

它**并非**试图将未来导向那些它恰好选择了最具「微邮票性」行动的状态；它只是在将未来导向那些它预测自己将实际拥有更多邮票的世界。

------

现在，让我给你讲第二个故事：

从前，一群天真的哲学家遇到了一群人类。人类似乎总是选择那些能给他们带来愉悦的行动。有时他们享用美食，有时他们体验性爱，有时他们赚钱以便日后消费于愉悦之事，但（至少在最初几周）他们总是采取那些导向愉悦的行动。

但后来有一天，其中一个人把大笔钱捐给了一家慈善机构。

「这怎么可能？」哲学家们问道，「人类是愉悦最大化者啊！」他们思索片刻后说：「啊，一定是他们从捐钱给慈善机构中获得的愉悦感，超过了他们本可以从花掉那笔钱中获得的愉悦感。」

再后来，一位母亲为了救自己的孩子，纵身跳到了一辆车前。

天真的哲学家们目瞪口呆，直到突然有人喊道：「我明白了！**选择那个行动**所带来的即时微愉悦，一定超过了——

------

人们会告诉你，人类总是且仅仅只做那些给他们带来愉悦的事情。人们会告诉你，利他主义根本不存在，人们永远只做自己想做的事。

人们会告诉你，因为我们被困在自己的头脑（认知）里，所以我们只能关心头脑内部的事物，比如我们自身的欲求和渴望。

但我有话要告诉你：事实上，你可以关心外部世界。

而且，你也能引导它。只要你愿意。