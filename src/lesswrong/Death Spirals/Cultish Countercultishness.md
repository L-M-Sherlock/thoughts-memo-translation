# 邪教式反邪

[邪教式反邪](https://www.readthesequences.com/Cultish-Countercultishness)

在当今社会，加入邪教或许是一个人可能遭遇的最可怕的境遇之一。最好的结局，也不过是身处一群赤诚却执迷的人之中——他们虽非恶意犯错，行事尚算安分——而你自己却倾注了大量的时间与金钱，最终落得一场空。说起来，这用来形容任何一家失败的硅谷初创公司也同样贴切。细思之下，那本就是段痛彻心扉的经历。所以没错，此事确实令人不寒而栗。

真正的邪教远比想象中可怕。他们以「情感轰炸」 为招募手段，专门针对正陷入个人危机的人群。此外，剥夺睡眠、强迫高强度劳动致其过度疲劳，或将招募对象安置在偏远的公社以隔绝其亲友。他们每天组织集会，勒令成员忏悔 「不洁思想」。邪教榨干招募对象*所有*钱财的情况屡见不鲜——包括毕生积蓄和每周薪水，迫使他们在衣食上完全仰仗邪教。不顺从者则遭受饥饿惩戒。这一切，都伴随着严重的洗脑与切实的伤害。

综合考虑到这些，对于那些因即将投身某项看似古怪的事业、且满心担忧*自己可能正加入邪教*而极度焦虑的人，我或许本该更同情他们。这本不该让我心烦意乱。但偏偏，我就是心烦。

第一点：「邪教」与「非邪教」并非如犬与猫般，是界限清晰的自然类别。若你查阅任何一份[邪教特征清单](http://www.prem-rawat-talk.org/forum/uploads/CultCharacteristics.htm)，都会发现其中有些条目完全可以用来描述政党和企业 —— 比如「怂恿成员将外部批评视作别有用心而心生质疑」「层级化的权威架构」。我曾就一些群体失败模式著述，例如[群体极化](https://www.readthesequences.com/The-Robbers-Cave-Experiment)、[幸福死亡螺旋](https://www.readthesequences.com/Affective-Death-Spirals)、[无批判性](https://www.readthesequences.com/Uncritical-Supercriticality)以及[信念蒸发冷却](https://www.readthesequences.com/Evaporative-Cooling-Of-Group-Beliefs)，这些模式似乎彼此助长，交织共生。当此类失败盘根错节、相互作用时，它们会融为一种「超级失败」，其荒谬程度远胜于各个单一部分的简单叠加——就像[战神金刚](https://www.youtube.com/watch?v=tZZv5Z2Iz_s)一样。但这并非「邪教」的*本质*，而是「邪教」的*吸引子*。

犬生来便携带犬的DNA，猫则生来便拥有猫的DNA。在如今的世界里，不存在介于两者之间的中间形态。（即便借助基因编辑技术，也绝非简单创造出一个一半含犬基因、一半含猫基因的生物就能实现。）多半不存在一套相互强化的「狗的特征」——一只猫不会因为沾染上其中一部分特征，就沦为「半狗」。

人类的大脑在进行类别划分时，似乎更偏爱「本质论」而非「吸引子理论」。人们总倾向于直接判定「这是邪教」或「这不是邪教」，一旦下了定论，分类任务便宣告完成。就像你观察到苏格拉底有十根手指、身着衣物且能说一口流利的希腊语，便可以断定「苏格拉底是人」，进而推导出「苏格拉底会被毒芹杀死」，而无需通过专门的血液检测来证实他的必死性。你就这样一劳永逸地确定了苏格拉底的「人性」。

但如果你观察到某一群体似乎表现出内群体与外群体的极化现象，且在他们「最钟爱之物」周围能看到明显的[晕轮效应](https://www.readthesequences.com/The-Halo-Effect)——这「最钟爱之物」可能是[客观主义](https://www.readthesequences.com/Guardians-Of-Ayn-Rand)、素食主义，或是[神经网络](http://thedailywtf.com/articles/No%2c_We_Need_a_Neural_Network)——那么*仅依据目前收集到的证据*，你无法推断他们是否已陷入「无批判性」的状态。你也无法推断他们的核心观点是对是错，或是虽有一定价值却并非如他们所想的那般有用。*仅依据目前掌握的信息*，你更无法判断他们在其他方面是否彬彬有礼，抑或他们是否会诱骗你与外界隔离，并剥夺你的睡眠与食物。「类邪教特质」并非要么全部存在，要么完全不存在。

如果你去看网上关于「*X*是邪教」「*X*不是邪教」的争论就会发现：一方会在网上找一份邪教特征清单，挑出一条符合的就说「所以这就是邪教！」；而辩护方则会找出一条不符合的特征反驳道「所以这不是邪教！」。

你无法用这种本质主义的思维方式，来精确描绘一个群体的动态推理过程。你必须逐一关注每个特征的具体情况。

此外，[谬误的反面并非真理](https://www.readthesequences.com/Reversed-Stupidity-Is-Not-Intelligence)。若你关注的是核心*观点*本身，而非仅仅是践行该观点的群体，便会知晓：明智的观点也可能有愚昧的追随者。不少新纪元运动者动辄大谈 「量子物理」，但这丝毫无损量子物理的内核。当然，荒谬的观点也会有愚昧的追随者。与二元本质论如影随形的，是这样一种偏颇逻辑：若你认定某个群体是 「邪教」，便推断其主张必定错误——只因 「错误主张是邪教的特征」，恰似猫必有皮毛般天经地义。可若你真正关注观点本身，就该[聚焦观点，而非盲从者](https://www.readthesequences.com/Hug-The-Query)。毕竟，「类邪教特质」更多是*群体*的烙印，而非*假说*的属性。

第二个谬误在于，当人们紧张地问道：「这不是邪教吧？」在我听来，他们似乎在寻求*理性思维的保证*。理性主义者不该过度执著于自身理性形象的观点，值得另撰专文探讨（参见[十二美德](https://www.readthesequences.com/The-Twelve-Virtues-Of-Rationality) [为何追求真理？以及…](https://www.readthesequences.com/Why-Truth-And) 及[两个邪教公案](https://www.readthesequences.com/Two-Cult-Koans)）。即便不深入探讨，人们也应明白：*焦虑地寻求保证*绝非审视理性问题的最佳心态。你不会怀抱[真诚的好奇心](https://www.readthesequences.com/The-Meditation-On-Curiosity)，也不会设法[满足你的疑虑](https://www.readthesequences.com/The-Proper-Use-Of-Doubt)。相反地，你会找到某个网路来源声称邪教利用睡眠剥夺控制人，注意到你最爱的团体并未采用此手段，便断言「这不是邪教。呼！」——这就像说「没有毛髮的就不是猫」。真是令人安心啊。

但[每个事业都想成为邪教](https://www.readthesequences.com/Every-Cause-Wants-To-Be-A-Cult)，无论事业本身是明智或愚昧。内群体-外群体二分法等现象皆属人性本质，并非[变种人](https://www.readthesequences.com/Are-Your-Enemies-Innately-Evil)的[特殊诅咒](https://www.readthesequences.com/Correspondence-Bias)。理性乃例外，非常态。你必须持续努力，才能在自然趋向熵增的状态中维持理性。若你认定「这不是邪教！」而松了口气，便不会持续抵禦那些*寻常*的邪教化倾向。你会断言邪教本质不存在，从而停止对抗邪教吸引子的熵增力量。

若你对邪教倾向极度敏感，便会竭力否认任何类似邪教的特征。但任何目标被视為正面的团体都可能陷入光环效应的风险，必须持续抗衡熵增效应，方能避免陷入情感死亡螺旋。这现象甚至存在于政党等常规机构——那些认定「自由派价值观」或「保守派价值观」能治癒癌症的人群便是例证。矽谷新创公司亦然，无论成败皆然。𬞟果用户与Linux用户皆不例外。光环效应不会因群体效应而合理化；若眾人齐赴悬崖，你仍不该跟随。此种谬误需被摒弃而非纵容。但若你过度忧虑「你确定这不是邪教吗？」，便会对任何邪教征兆避之唯恐不及——因為那意味著你身陷邪教，而「这不是邪教！！」。如此一来，你将看不见当今𢧐场上，那些「寻常」的邪教倾向正悄然蔓延，或被奋力遏止的实况。