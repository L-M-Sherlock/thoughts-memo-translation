# 无界标度、陪审团巨额裁决与未来预言

原文：[Unbounded Scales, Huge Jury Awards, and Futurism](https://www.readthesequences.com/Unbounded-Scales-Huge-Jury-Awards-And-Futurism)

「心理物理学」（Psychophysics），名字听着可能有点玄乎，但它其实是一门正经学科，研究的是物理刺激与主观感知之间的联系。比如，当你在空气中释放声能——也就是制造噪音——那么在别人听来，这声音究竟**有多响**呢？这与声能之间存在怎样的函数关系？要让听者感觉声音响了一倍，你又需要向空气中额外输出多少倍的声能呢？答案可不是两倍，而是差不多八倍。

声能和光子都很容易直接测量。但当你想知道声音刺激**听起来**有多响、光源**看起来**有多亮时，通常就需要询问观察者了。这可以用有界标度来完成，例如从「非常安静」到「非常响」，或从「非常暗」到「非常亮」。你也可以用无界标度，也就是没有上限的标度，其零点为「完全听不见」或者「完全看不见」，但数值由此无限递增。当采用无界标度时，通常会给观察者呈现一个恒定的刺激作为参照，并预先为其赋予一个固定的数值，即**模数**（modulus）。例如，将某个声音的响度值指定为 10 作为模数；观察者就可以把听起来有它两倍那么响的声音记为 20。

事实证明，这是一种相当可靠的方法。但如果你给受试者一个无界标度，却不提供模数作为参照，会怎样？一个从零到无穷、没有任何固定值参考点的标度？那他们自然会凭感觉设定自己的模数。不过，不同受试者对各个刺激给出的数值**比率**仍然会表现出可靠的一致性。举例来说，受试者 *A* 说声音 *X* 的响度是 10，声音 *Y* 的响度是 15。如果受试者 *B* 说声音 *X* 的响度是 100，那么我们就能很有把握地猜测，他会给声音 *Y* 一个 150 左右的响度值。但如果你不知道受试者 *C* 用什么作为自己的模数——或者说他的「换算因子」——那么你就根本无法猜出他对声音 *X* 会给出什么数值。可能是 1，也可能是 1000。

对于评价**单个**声音的受试者来说，如果使用**无界**标度，并且**没有**固定的比较标准，那么他们打分时出现的差异，几乎完全可以归因于其任意选择的模数，而不是声音本身的性质。

「唔，」你心想，「这听起来跟陪审团在商定惩罚性赔偿金时的情景可太像了。怪不得赔偿金额的差异那么悬殊！」这个类比很有意思，但你该如何着手通过实验来证明这一点呢？

Kahneman 等人向 867 名具备陪审员资格的受试者展示了一些法律案件说明（例如，小孩衣服着火），并要求他们完成以下三项任务中的一项：

1. 在有界标度上，评定被告行为的恶劣程度；

2. 在有界标度上，评定被告应受惩罚的程度；或

3. 给出惩罚性赔偿金的具体美元金额。[1]

结果你猜怎么着，虽然受试者们在恶劣程度和惩罚程度的评定上彼此高度一致，但他们给出的惩罚性赔偿金额却是五花八门、天差地别。然而，他们对这些赔偿金额的**排序**——也就是从最低赔偿额到最高赔偿额的顺序——在不同受试者之间又表现出了高度的一致性。

具体到数据上：在「惩罚」程度量表上，由具体案情——即呈现给多个受试者的同一个案件——所能解释的评分差异，即便是原始分数，也达到了 0.49。对于赔偿金额的**等级排序**，这一可解释的差异比例为 0.51。而对于**原始美元**金额，该比例竟然只有 0.06！

换句话说：只要你知道具体的案情——比如前文提到的那个衣服着火的孩子——你就能比较准确地预测出它的惩罚评级，也能大致判断出这笔赔偿金相对于其他案件的**位次排序**，但赔偿金的具体数额本身，却是完全无法预测的。

即便是将十二个随机抽取的答案取中位数，也收效甚微。

因此，陪审团的惩罚性赔偿金裁决，与其说是在评估经济价值，不如说是在表达态度——它是在一个没有标准模数的无界标度上，对恶劣程度进行的一次心理物理学测量。

我发现，许多**对未来的预测**同样如此，最好也将其看作是一种态度的表达。就拿这个问题来说：「我们还要过多久才能拥有人类水平的人工智能？」我听到的回答简直千差万别。有一次我印象深刻，某位主流 AI 圈内人士跟我说了个数：「500 年。」（！！）

要说实现人工智能所需的时间为何**不太好预测**，这本身就说来话长了。但说出「500 年」的那个人，总不见得是真能预见未来才这么说。而且他也不可能是通过那种滥用摩尔定律的标准伪科学方法计算出这个数的。那么，500 这个数字到底**意味**着什么呢？

依我猜测，这就好比是在问：「按 0 代表『毫无难度』来评级，你**感觉**人工智能这项难题有多难？」假如这是有界标度，那么任何一个理性的人都会选最右端的「极难」——当你对一件事束手无策时，你总会**感觉**它极其困难。然而实际上，他们面对的是没有标准模数的无界标度。于是人们只好凭空想一个数来代表「极难」，这个数可能是 50、100，甚至 500。然后给这个数后面安上个「年」的单位，就成了所谓的未来预测。

「你感觉人工智能这项难题有多难？」并非唯一可被替换的问题。还有些人的回答，仿佛我问的是「你对人工智能有多乐观？」，只不过在他们的逻辑里，给出的年限数字越小，就代表越乐观——当然，他们也会在数字末尾加上个「年」字。但要说这些所谓的「时间预测」除了是在一个没有标准模数的无界标度上表达态度之外，还能代表任何其他东西，那我可真是没看出来。