# 从虚构证据中进行推广：一种逻辑谬误

原文：[The Logical Fallacy of Generalization from Fictional Evidence](https://www.readthesequences.com/The-Logical-Fallacy-Of-Generalization-From-Fictional-Evidence)

每当我试图向人们介绍高级人工智能这个话题时，十有八九，我听到的第一反应是什么？

「哦，你是说像**《终结者》**系列电影 / **《黑客帝国》** / 阿西莫夫笔下的机器人那样吧！」

而我则会回答：「嗯，不，不完全是。我尽量避免犯那种从虚构证据中进行推广的逻辑谬误。」

有些人一听就懂，随即会心一笑。另一些人则会为自己援引这些例子的做法辩护，不认为这是一种谬误。

那么，用电影或小说作为讨论的切入点究竟错在哪里呢？毕竟，没有人声称这些作品是**真实**的。这其中何来谎言，又何谈违背了理性主义的原则呢？科幻小说代表了作者对未来的一种想象性尝试；我们为什么不直接利用这些已有的思考成果，而非要从头开始呢？

在精确严谨的理性思维之路上，并非每一步失误都源于对谬误的全然相信；有些错误会以更不易察觉的方式发生。

首先，我们必须摒弃这样一种观念，即认为科幻小说代表了一种成熟的、理性的未来预测尝试。即使是最为严谨的科幻作家，其首要身份依然是故事讲述者；而讲故事的要求与进行预测的要求并不相同。正如 Nick Bostrom 所[指出](http://www.nickbostrom.com/existential/risks.html)的：[1]

> 你上一次看到一部讲述人类突然灭绝（毫无预警且未被其他文明取代）的电影是什么时候？尽管这种情况发生的概率可能远高于人类英雄成功击退怪物或机器人战士入侵的概率，但观看这样的电影并不会带来多少乐趣。

因此，虚构作品中存在着[特定的扭曲](http://www.overcomingbias.com/2006/12/biases_of_scien.html)。然而，仅仅试图修正这些特定的扭曲是远远不够的。一个故事，**绝非**一种理性的分析尝试，即便出自最严谨的科幻作家之手也是如此，因为故事并不运用概率分布。我试举一例说明：

> 鲍勃·默克尔瑟德小心翼翼地滑进外星飞船的舱门，他先向右瞥了一眼，然后向左（或者先左后右），查看是否还有可怕的太空怪物残留。他身边放着唯一被证实对太空怪物有效的武器：一把有 30% 概率是纯钛锻造的太空剑，有 20% 概率是一根普通的铁撬棍，还有 45% 概率是在巨石阵冒烟的废墟中发现的一个闪闪发光的黑色圆盘，其余 5% 的概率则分散在太多细枝末节的可能性上，此处不便一一列举。

>

> 默克尔瑟德（尽管苏珊·威夫尔当时在场的可能性也相当大）向前走了两步或向后退了一步，就在这时，一声巨响划破了黑色气闸舱的寂静！也可能是白色气闸舱那安静的背景嗡鸣声！尽管安弗和乌菲（1997）认为默克尔瑟德在此时已被吞噬，但斯帕克尔巴克尔（2003）指出——

故事中的角色可以一无所知，但**作者**却不能说出那三个充满魔力的字眼：「我不知道」。主人公必须在未来纷繁的可能性中穿行出一条单一的路径，这条路径充满了赋予故事血肉的[种种细节](https://www.readthesequences.com/Burdensome-Details)，从威夫尔那恰如其分的未来主义女权观念，一直到她耳环的颜色。

然后，所有这些冗余的细节和可疑的假设都被一股脑儿地打包起来，并贴上一个[简短的标签](https://www.readthesequences.com/Occams-Razor)，从而造成一种错觉，仿佛它们是一个[不可分割的整体](https://en.wikipedia.org/wiki/Package-deal fallacy)。

对于那些答案空间极为广阔的问题而言，最大的困难并非在于**验证**正确答案，而在于一开始就**在答案空间中将其定位**。如果有人一上来就问人工智能是否会像《黑客帝国》里那样把我们关进培养皿，那他无异于直接跳到了一个包含 100 比特信息的复杂命题上，却没有提供相应的 98 比特证据来证明这个可能性在巨大的答案空间中值得被明确地拿出来讨论。要知道，在最初的 98 比特证据之后，往往只需要再多一点点证据，就能使这个可能性接近板上钉钉，这足以说明几乎所有的关键工作都集中在哪个阶段。

这个定位值得明确考虑的可能性的「初步」阶段，包括了诸多步骤：权衡你已知和未知的信息，你能预测和不能预测的方面，刻意避免[荒谬偏见](https://www.readthesequences.com/Stranger-Than-History)并[拓宽置信区间](https://www.greaterwrong.com/lw/j6/why_is_the_future_so_absurd/)，认真思考哪些问题才是关键所在，努力校正可能的黑天鹅事件并设想那些（曾经）未知的未知。直接跳到「**《黑客帝国》：是耶？非耶？**」的讨论，则**完全忽略了以上所有步骤**。

任何专业的谈判者都深知，控制一场辩论的议题设置，几乎就等同于控制了这场辩论的结果。如果你一上来就联想到《黑客帝国》，脑海中浮现的便是行进中的机器人大军在一番苦战后击败人类的景象——而不是一个超级智能体弹指间便施展出纳米技术的场景。这种联想将焦点集中在一种「我们对抗他们」的斗争模式上，从而将注意力引向诸如「谁会赢？」「谁应该赢？」以及「人工智能真的会是那个样子吗？」这类问题。它营造出一种纯粹娱乐的氛围，一种「你对未来有何惊人构想？」的探讨氛围。

而在这种空洞的回响中被遗失的，则是：对「人工智能」可能实现的多种心智设计方案的考量；未来发展对初始条件的依赖性；远超人类的智能所具有的[强大力量](https://www.readthesequences.com/The-Power-Of-Intelligence)及其[不可预测性](https://intelligence.org/2007/09/30/three-major-singularity-schools/)的论证；以及人们严肃对待整个议题并试图为此采取行动的可能性。

倘若某个阴险的辩论操纵者认定，通过迫使讨论者从一开始就去反驳**《终结者》**中的设定，最能达成**他们**所偏好的结果，那么他们在扭曲讨论框架方面可谓是手法高明了。在关于枪支管制的辩论中，全国步枪协会的发言人不希望被冠以「射击狂人」的称号，而反枪支一方的代表也不愿被称为「鼓吹解除受害者武装者」。那么，你又为何要容许好莱坞的编剧们——即便他们是无心之失——进行同等级别的框架扭曲呢？

记者们倒不会直接告诉我：「未来将会像**《2001 太空漫游》**那样。」但他们会问：「未来是会像**《2001 太空漫游》**呢，还是会像**《人工智能》**那样？」这就如同问「我们是应该削减残疾退伍军人的福利，还是应该对富人增税？」一样，是一个极具误导性的框架设定问题。

在人类的远古生存环境中，并没有活动影像这种东西；你亲眼所见即为真实。仅仅瞬间瞥见一个词语，就能[启动](https://www.readthesequences.com/Priming-And-Contamination)我们的思维，使与之相关的想法更容易被[提取](https://www.readthesequences.com/Availability)，并且已被证明这对我们的概率判断会产生强烈影响。那么，你认为一部长达两小时的电影会对你的判断力造成多大的浩劫呢？即便刻意集中精神去消除这种影响也已属不易——又何苦要引狼入室呢？在国际象棋或围棋中，每一步废棋都是一种损失；在理性思维中，任何非基于证据的影响（平均而言）都会导致熵增。

电影观众是否能成功地[不相信](https://www.readthesequences.com/Do-We-Believe-Everything-Were-Told)他们所看到的内容呢？据我所知，很少有电影观众会表现得仿佛他们**直接**观察到了地球的未来。看过《终结者》系列电影的人，并没有在 1997 年 8 月 29 日那天躲进辐射避难所。但是，那些犯下这种逻辑谬误的人，其行为举止却仿佛他们看到的是电影情节发生在**某个其他**星球上；不是地球，而是某个与地球相似的地方。

当你说：「假设我们建造一个非常聪明的人工智能，」他们便会说：「可那在**《终结者》**里不是导致了核战争吗？」在我看来，这种推理方式，甚至连说话的语气，都与那些可能会说：「可那不是导致了半人马座阿尔法星上的核战争吗？」或者「那不是导致了十四世纪意大利城邦皮科洛的覆灭吗？」的人如出一辙。人们并不相信电影本身，但电影中的情节却是[唾手可得](https://www.readthesequences.com/Availability)的参照。它不被视为预言，而被当作一个具有启发性的历史案例。历史会重演吗？谁知道呢？

在最近一次关于智能爆炸的讨论中，有人提到弗诺·文奇似乎并不认为脑机接口能大幅提升智能，并引用了其著作《实时放逐》中的角色 Tunç Blumenthal 为例，这位角色是最高级的时空旅行者，但看起来似乎并没有那么强大。我当时义愤填膺地反驳道：「但是 Tunç 丢失了他大部分的硬件设备！他已经残废了！」话一出口，我猛地一怔，心想：我这到底在说些什么**鬼话**。

难道这个问题本身不应该就事论事地进行探讨，而非要管文奇是如何刻画他的角色的吗？Tunç Blumenthal 并非「**残废**」，他是**虚构**的。我本可以说：「文奇选择将 Tunç 刻画成残废的状态，其原因可能与他个人对未来的最佳预测有关，也可能毫无关联。」这样说才能给予他作为作者的选择恰如其分的证据权重。我不能直接说：「Tunç **残废了**。」因为根本就不存在一个「**曾经是**」的 Tunç Blumenthal。

在我这篇文章开篇的初稿中，我特意保留了我犯的一个错误：「另一些人则会为自己援引这些**例子**的做法辩护，不认为这是一种谬误。」但是，《黑客帝国》并**不是**一个例子！

与此类似的一个缺陷是「从想象的证据出发进行论证」的逻辑谬误：「嗯，如果你**真的**走到了彩虹的尽头，你**就**会找到一罐金子——这正好证明了我的观点！」（基于已预测但未观察到的证据进行信息更新，这在数学上正是[后见之明偏见](https://www.readthesequences.com/Fake-Causality)的镜像反映。）

大脑拥有许多从观察中进行概括的机制，并不仅仅是可得性启发法。你看到三只斑马，便会形成「斑马」这个类别，而这个类别本身就蕴含了一种自动的感知推断。那些形似马、身披黑白条纹的生物被归类为「斑马」，因此它们被认为是跑得快且美味可口的；人们会预期它们与先前观察到的其他斑马具有相似性。

于是，人们看到（活动影像中的）三个博格人，他们的大脑便会自动创建「博格人」这个类别，并自动推断出拥有脑机接口的人类也属于「博格人」这一类，将会与他们观察到的其他博格人相似：冷酷无情、缺乏同情心、身着黑色皮革、迈着沉重的机械步伐。记者们并不相信未来**真的**会出现博格人——他们不相信**《星际迷航》**是预言。但是当有人谈论脑机接口时，他们便会想：「未来会出现博格人吗？」而不是去想：「我怎么知道计算机辅助的心灵感应会让人变得不那么友善？」也不是去想：「我从未见过博格人，其他人也从未见过。」更不是去想：「我正在基于**字面上**完全为零的证据形成一种种族刻板印象。」

正如乔治·奥威尔在谈及陈词滥调时所[言](https://www.readthesequences.com/Rationality-And-The-English-Language)：[2]

> 至关重要的是让意义选择词语，而不是反过来……当你在思考某种抽象事物时，你更倾向于从一开始就使用既有的词语，除非你刻意努力去避免，否则现存的语汇表达方式便会蜂拥而至，替你完成思考，其代价则是模糊甚至改变你原有的含义。

然而，在我看来，借鉴他人想象力所带来的**最**具破坏性的影响在于，它会阻碍人们运用自己的想象力。正如罗伯特·波西格所[言](https://www.readthesequences.com/Original-Seeing)：[3]

> 她之所以思路受阻，是因为她试图在写作中重复那些她早已听闻的事情，正如他第一天教学时也曾试图重复那些他早已准备好的说辞一样。她之所以想不出任何关于博兹曼市可写的内容，是因为她回忆不起任何她曾听过的、值得重复的东西。她奇怪地没有意识到，在写作时，她完全可以为自己进行全新的、直接的观察和感受，而不必首先考虑别人先前都说过些什么。

记忆中的虚构情节蜂拥而至，替你完成了思考；它们取代了**亲身的观察**——这便是所有便利之中最为致命的一种。