# 赋能环境的原语；机器生成学习提示的初步探索

原文：[A primitive for enabling environments; early work on machine-generated prompts | Patreon](https://www.patreon.com/posts/116921064)

我正在构思一种全新的间隔重复系统——一种创新的赋能环境——它的核心原语与现有系统有本质区别。

# 新核心原语的必要性

现有间隔重复系统的核心原语是抽认卡。当你想记住某个信息时，你需要将其转化为抽认卡的形式，然后添加到系统中。系统只识别抽认卡，不理解你想记忆的具体内容，更不了解这些内容与你正在学习的其他知识之间的联系。

对于记忆简单事实，如国家首都或外语词汇，这种方法还算行之有效。但间隔重复系统的重要性在于它能支持多样化的学习，帮助你更深入地理解和内化各种复杂概念。然而，问题在于——根据我的经验——当学习内容越偏离简单的事实-抽认卡对应模式，这些系统的效果就越不理想，使用起来也越发困难。

Michael Nielsen 和我在之前的研究中[指出](https://numinous.productions/ttft)，「记忆系统」这一概念比「间隔重复系统」更能全面地涵盖这一领域。后者仅强调了一种特定的学习方法，而认知心理学家已经揭示了诸多关于人类记忆的深层规律，我们应该充分利用这些研究成果。选择「记忆系统」这一表述的另一个原因是，它更贴近我们的实际需求。我们需要的是一个能帮助我们形成牢固记忆的系统。（实际上，我们的需求可能更为复杂，这一点我们稍后会详细探讨。）

对于基础词汇的记忆，单纯的间隔重复可能已经足够有效。然而，对于更复杂的概念，我发现仅仅依靠抽认卡往往只能形成不够稳固的记忆。当我多次接触同一张抽认卡后，其中特定的表述方式很容易成为强烈的提示信号。这时，我对答案的回忆可能并非源于对内容的真正理解，而是一种条件反射式的模式匹配。一个真正有效的记忆系统应该能够通过多样化的提示、不同的角度和各种关联来呈现同一个概念，帮助我们从多个维度编码记忆，从而构建起稳固而灵活的知识结构。

让我们再次拓宽视野。通常，我追求的不仅仅是记忆，更重要的是**学习**。我希望所学的主题能够鲜活实用。我期望能够灵活自如地运用所学知识。我渴望随着时间推移，对知识的理解能不断深化。我希望能够洞察新的含义，激发新的想法。现代间隔重复系统的发明者 Piotr Wozniak 曾[提出应该先学习后记忆](https://www.supermemo.com/en/blog/twenty-rules-of-formulating-knowledge)。然而，根据我的经验和对认知结构的理解，我认为这是一个持续进行的并行过程。当我们练习和阐释所学内容时，我们会建立新的联系，加深理解。记忆与这个过程密不可分，而非独立于学习之前或之后的步骤。[1]因此，「记忆系统」这个词已不足以概括这个过程。我们理想中的系统需要一个更宽泛的名称——这也是我经常使用「[赋能环境](https://andymatuschak.org/hmwl)」这个术语的原因之一。

这些内容听起来都很注重认知层面。事实上，我放入间隔重复系统的许多内容并非如此。我可能会记录下与朋友共进晚餐时的一个富有洞察力的观察，一句令人回味的名言，或者某人令我惊讶的行为。这里的重点并非单纯的记忆。而是为了改变——通过消化这些经历，使我在未来的感受或行动有所不同。实际上，这一点也适用于我更传统的学习方式。当我学习音乐理论时，我的目标不仅仅是学习知识；我希望在演奏音乐时能有不同的感受和表现。当我研究一个历史人物时，我不仅仅是想了解事实；我希望将他们看待世界的方式融入我自己的视角中，从而以新的方式体验世界。这样，我就能以一种微小但真实的方式，成为一个不同的人。[2]一个专注于这种目标的系统，将在更深层次上成为一个「赋能环境」。

# 一种替代的原语：情境化的想法

在阐明了这些崇高的目标之后，我现在可以表达我对抽认卡的主要不满：它们是静态的。它们就像「[死鱼](https://vimeo.com/64895205)」一样缺乏活力。要建立牢固的记忆，需要多样化的提示和联系；要实现深入的学习，需要不断提升深度和复杂性；要真正内化知识，需要具体的语境和生动的体验。

为了给这些系统注入活力，我认为我们需要引入新的核心机制。目前的间隔重复系统主要围绕着抽认卡运作——添加、组织和安排它们。我认为我们应该从更本质的层面着手。如果我们希望复习过程能够随时间推移而变化、深化并建立联系，仅仅提供静态任务是远远不够的。事实上，如果我们的目标是促进知识迁移，我们就不应该预先设定固定的任务：因为迁移学习需要惊喜元素。我们需要某种方式来指向激发任务的原始想法，并将其置于启发我们的具体情境中，这样才能随着时间推移产生一系列不断变化和深化的任务。[3]

在阅读一本书时，标记一个重要想法最自然的方式就是直接在文本上指出来，比如用荧光笔高亮某个段落，或者在页边写下我们认为有意义的评注。同样，当我们回顾一次对话或某个经历时，也可以在日记或笔记中采用类似的方法。

具体而言，我设想的这个新的原语——不妨称之为「情境化的想法」——将取代传统的问答格式，它包含以下内容：

- 指向相关上下文的链接，包含完整文本；例如一本书、一篇日记等。

- 在该上下文中标记需要理解和吸收的想法的范围（可能是单个或多个范围）；就像你在书中做的高亮标记。

- 一条可选的额外注释，用于阐明你的意图或兴趣所在；类似于你在高亮旁边写的边注。

接下来，系统会基于这些输入，以及与相关语境中其他具象化概念的联系，随着时间推移合成适当的学习活动。

这一过程基本上模仿了专业教学设计师的工作：他们根据文本中引入的一组「知识点」，设计一系列活动（包括已解决的示例、练习和反思等），并随时间推移以多样化和逐步深入的方式呈现这些活动。在某些情况下，这些活动序列甚至可能根据你的表现进行调整，不过很少有课程能像间隔重复系统那样有效地增强你的记忆。

我提出的系统与传统方法的关键区别在于，它将控制权从教学设计师转移到了用户手中。这是我过去几年运用助记媒介工作中得到的最重要启示：[具有自主学习动力的成年读者很少愿意被动地接受作者规定的学习内容](https://www.patreon.com/posts/revamping-medium-55309960)。人们从文本中寻求的内容各不相同，他们的学习目标也不尽相同。有的学习者想掌握定理，有的则希望能够证明这些定理。他们的知识背景也各不相同。有的学习者在某一方面需要大量强化，而另一些则在其他方面需要加强。此外，他们对不同子主题的兴趣也各异。一个学习者可能会略读某个章节，而另一个学习者却会对同一章节孜孜不倦，反之亦然。

这些见解促使我[去年进行了「魔法」荧光笔的实验](https://www.patreon.com/posts/highlight-driven-90101210)，并激发了一个令人兴奋的想法：如果我们能让荧光笔真正实现人们**梦寐以求**的功能，会怎么样呢？调查显示，学生最青睐的学习方法通常是重读和标记重点。然而，如果列出最有效的学习方法，这两种方法往往垫底。尽管如此，标记重点的感觉却很棒：它是一种表达兴趣的方式，一种参与学习的方式，一种在文本上留下自己印记的方式。人们以为标记重点会帮助他们内化学习材料。但事实上，它（在大多数情况下）并不奏效。不过，也许我们可以改变这一现状：你可以使用特殊的荧光笔将「情境化的想法」添加到你的知识库中，然后系统会确保你能够真正内化这些材料。

# 好吧，好吧，我承认：机器生成的提取练习任务

当我在 2022 年开始写这个想法时，我的看法与现在大不相同。当时，大型语言模型（LLMs）无法为源文本的特定部分生成优质的提取练习任务。事实上，直到 2024 年底，LLMs 在这方面仍然表现欠佳。但现在，我正在与 [Ozzie Kirkby](https://kirkbyo.com/) 合作开展一个项目，旨在解决这个问题。

许多人都曾对这个问题做出过小规模尝试，但我尝试过的解决方案都未能达到令人满意的效果。我一直对这个问题持谨慎态度，主要是因为不认同主流的激励框架：效率、便捷、易用。在我看来，这些目标过于急于求成。我追求的是本质上的突破。诚然，减少制作抽认卡的成本是件好事，但我更希望这些系统能够真正提升学习效果——形成更牢固的记忆、更深入的理解和更全面的知识内化。

一个全新学习模式的机会，这才是更值得探索的方向。我期望的是一种类似于间隔重复系统的东西，但其复习活动能够随时间推移而变化、深化并相互关联。这样的系统要么需要极其昂贵的逐项内容定制，要么需要机器生成任务。而只有机器生成的任务才能为每个人的独特背景量身定制学习活动。

因此，机器生成任务成为了必然选择！Ozzie 和我已经合作研究这个项目约六周了。虽然仍处于起步阶段，但我想与大家分享一下我们目前的方法和心得。

首先：当前的人工智能模型在生成简单事实以外内容的有效任务时，并不能自动表现出色，至少仅依靠提示工程和少量样本示例是无法实现的。这一现象是可以理解的。很少有人使用记忆系统来存储简单事实之外的信息，因此训练数据集中这类例子寥寥无几。虽然存在题集和练习题，但提取练习任务则完全是另一种语言。而且，即便有特定的重点内容和完整的源上下文，模型在确定——决定读者可能想要**关于**高亮范围内哪些内容的任务——方面也表现得相当糟糕。

尽管如此，这些模型**偶尔**也能生成结构完善、目标明确的任务。有鉴于此，我们开始着手训练一个分类器，用于评估任务的质量。我们的理论基础是，至少在初期阶段，即使模型很少产生高质量输出也无妨，关键在于我们能够筛选出低质量的任务。随后，借助这种方法，我们就能够随时间推移评估不同的模型和架构，从而「放大」我们在任务编写方面相对稀缺的专业判断能力。

与大多数机器学习流程一样，数据成为了一个关键的制约因素。我们首先手动构建了一个包含数百个「情境化概念」的数据集，其中包括源内容、重点标注范围、提取练习任务以及分类评分。随后，我们通过人工评分的方式，将大语言模型生成的任务（包括高质量和低质量样本）纳入数据集，使样本总量超过两千个。目前的结果显示，分类器在同一源文本范围内表现良好（对于预留的测试样本），但在处理全新的源文本时，其泛化能力却明显下降。

因此，我们正在收集更多数据。我们设计了一个高效的工作流程：

- 在阅读 PDF 或网页文章时，我们使用 Hypothes.is 工具对内容进行高亮标注

- 随后，一个机器人会针对这些高亮部分自动生成相关任务建议

- 对于每个机器人生成的建议，我们会给出以下反馈：一个机器可识别的「评分」；自由格式的批评性意见；（可选）对同一任务的「修正」重写版本；以及（可选）我们发现的问题类型标签（例如过分关注无关紧要的细节）

- 如果机器生成的所有任务建议都不理想，我们会亲自回复高亮部分，提出我们期望的任务

这个工作流程中产生的分类评分和人工编写的任务会被用来进一步改进分类器，从而提升输出质量。我们还会将批评性意见和人工优化的示例用作少样本学习或模型微调的材料，以改进任务生成能力。我们希望随着时间推移，我们能够接受更多模型的输出，这将降低人工反馈的成本，进而让我们能够收集更多数据，形成良性循环。一旦输出变得相对可靠，我们就可以通过众包方式获取标签，进一步加快这一过程。

# 下一步计划

我的长远目标是推动我们向我此前描述的更具动态性的学习系统迈进。不过就近期而言，我预计这个项目将为现有间隔重复系统的用户带来显著便利。我们计划开发一个界面，让用户能够轻松地标注文本，并将由此生成的学习任务导入到 Anki、Mnemosyne 等工具中。当然，这一切都建立在我们的处理流程能够达到理想性能的前提下。无论如何，我们一定会将我们的数据集和代码开源。

即便在传统抽认卡生成的有限范畴内，要与现有系统实现良好的整合，最终也需要进行更深层次的改变。在理想的整合方案中，用户无需在阅读过程中评估机器生成的学习任务。他们只需专注于阅读和标注，然后在之后进行复习。这里的难点在于，有时一处标注可能会涉及几个不同的概念——而用户可能并不想全盘接受。因此，用户需要就目标定位、期望的深度等方面向系统提供反馈。

要实现这一点，最简单的方法是让用户在阅读过程中评估机器生成的任务，但我可以凭经验告诉你：这样做会让人感到不适。更好的做法是在复习时提供反馈。当然，这需要更复杂的系统整合。从长远来看，如果按我的设想，让用户评估和批准机器生成的任务将失去意义，因为任务会随每次复习而变化。这是一种全新的概念模型。

在设计动态回顾系统时，机器生成的任务虽然必不可少，但仅此还不够。初步实验表明，大型语言模型（LLMs）能够相当可靠地生成已知高质量任务的简单变体，从而避免简单的模式匹配问题。然而，我们的目标是创造能够随时间推移不断深化理解、建立联系并重新构建语境的任务。这需要专门的研究和开发流程。

————————

我由衷感谢 Ozzie Kirkby 与我一同探索这个领域，就相关话题进行了富有洞察力的讨论，并对草稿提出了宝贵意见。同时，也要感谢 David Holz 激发我深入思考分类器的相关问题。

————————

[1] 为了阐明观点，我可能过于简化了 Piotr 的看法。我想他大体上会认同我的论述。他可能会（合理地）指出，那些新的联系和更深入的理解实际上是不同的知识单元——因此，实际发生的是一系列相关的学习/记忆阶段对。从系统设计的宏观角度来看，我的观点依然成立：学习和记忆作为一个持续过程是紧密交织的；一个优秀的学习系统应该能够支持这个动态过程。

[2] 这个框架与我上个月在文章中描述的项目[迈向可扩展的闪光培养](https://www.patreon.com/posts/towards-scalable-115120980)有一些明显的联系。

[3] 这个想法已经酝酿了一段时间；早期相关讨论请参见：

- [从 2022 年夏的助记媒介原型中学到的经验教训](https://www.patreon.com/posts/lessons-from-73309142) (Oct ‘22)

- [更灵活的实践可能产生更流畅的理解](https://www.patreon.com/posts/fluid-practice-83882597) (May ‘23)

- [高亮引导的实践与理解辅助](https://www.patreon.com/posts/highlight-driven-90101210) (Sep ‘23)

- [我们如何学习？](https://andymatuschak.org/hmwl) (May ‘24)